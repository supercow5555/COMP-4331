{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "Note: \n",
    "1. It is ok to define more helper functions, but not necessary for finishing the homework.\n",
    "2. The imported libraries are sufficient to complete the TODO intructions. Please consult TA Vincent Cheng for permission to use additional libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP structure you built is as follow: \n",
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        input_layer = 1*28*28           #784\n",
    "        hidden_layer_1 = 300\n",
    "        hidden_layer_2 = 100\n",
    "        output_layer = 10\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features= input_layer, out_features= hidden_layer_1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features= hidden_layer_1, out_features= hidden_layer_2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features= hidden_layer_2, out_features= output_layer)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        x: batch x 1 x 28 x 28\n",
    "        return prediction\n",
    "        \"\"\"\n",
    "\n",
    "        x = torch.flatten(x, start_dim= 1)      # batch x 784\n",
    "        x = self.fc1(x)                         # batch x 300\n",
    "        x = self.relu1(x)                       \n",
    "        x = self.fc2(x)                         # batch x 100\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)                         # batch x 10\n",
    "        return x\n",
    "\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code way of doing (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters are: 266610\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters are:\", count_parameters(mlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (c)\n",
    "Note: run this code after code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def count_acc(logits, label):\n",
    "    \"\"\"\n",
    "    :param logits: n * c; n=num of samples, c=number of classes\n",
    "    :param label: n\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    return (pred == label).float().mean().item()\n",
    "\n",
    "def train_a_model(model, num_epoch=3):\n",
    "    for i_epoch in range(num_epoch):\n",
    "        model.train(True)\n",
    "        loss_list = [ ]\n",
    "        acc_list = [ ]\n",
    "        for i_iter, (x, y_true) in enumerate (train_loader, start=1):\n",
    "            y_pred = model.forward(x)\n",
    "            loss = F.cross_entropy(y_pred, y_true)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # for printing messages during training\n",
    "            acc = count_acc(y_pred, y_true)\n",
    "            loss_list.append(loss.item())\n",
    "            acc_list.append(acc)\n",
    "            if i_iter % 200 == 0:\n",
    "                loss_avg = np.sum(loss_list) / len(loss_list)\n",
    "                acc_avg = np.sum(acc_list) / len(acc_list)\n",
    "                msg = \"TRAIN epoch: {}/{} iter {}/{} \\t loss: {:.4f}, acc: {:.2f}\".format(\n",
    "                    i_epoch, num_epoch, i_iter, len(train_loader), loss_avg, acc_avg*100)\n",
    "                print(msg)\n",
    "                loss_list = []\n",
    "                acc_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP structure you built is as follow: \n",
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "TRAIN epoch: 0/3 iter 200/2400 \t loss: 1.2844, acc: 66.00\n",
      "TRAIN epoch: 0/3 iter 400/2400 \t loss: 0.4644, acc: 86.54\n",
      "TRAIN epoch: 0/3 iter 600/2400 \t loss: 0.3898, acc: 88.26\n",
      "TRAIN epoch: 0/3 iter 800/2400 \t loss: 0.3025, acc: 90.86\n",
      "TRAIN epoch: 0/3 iter 1000/2400 \t loss: 0.3032, acc: 91.00\n",
      "TRAIN epoch: 0/3 iter 1200/2400 \t loss: 0.2457, acc: 92.72\n",
      "TRAIN epoch: 0/3 iter 1400/2400 \t loss: 0.2341, acc: 92.62\n",
      "TRAIN epoch: 0/3 iter 1600/2400 \t loss: 0.2126, acc: 93.54\n",
      "TRAIN epoch: 0/3 iter 1800/2400 \t loss: 0.2018, acc: 93.92\n",
      "TRAIN epoch: 0/3 iter 2000/2400 \t loss: 0.2029, acc: 93.90\n",
      "TRAIN epoch: 0/3 iter 2200/2400 \t loss: 0.1749, acc: 94.66\n",
      "TRAIN epoch: 0/3 iter 2400/2400 \t loss: 0.1174, acc: 96.46\n",
      "TRAIN epoch: 1/3 iter 200/2400 \t loss: 0.1320, acc: 96.18\n",
      "TRAIN epoch: 1/3 iter 400/2400 \t loss: 0.1359, acc: 96.06\n",
      "TRAIN epoch: 1/3 iter 600/2400 \t loss: 0.1502, acc: 95.70\n",
      "TRAIN epoch: 1/3 iter 800/2400 \t loss: 0.1178, acc: 96.46\n",
      "TRAIN epoch: 1/3 iter 1000/2400 \t loss: 0.1271, acc: 95.94\n",
      "TRAIN epoch: 1/3 iter 1200/2400 \t loss: 0.1149, acc: 96.40\n",
      "TRAIN epoch: 1/3 iter 1400/2400 \t loss: 0.1154, acc: 96.46\n",
      "TRAIN epoch: 1/3 iter 1600/2400 \t loss: 0.1131, acc: 96.66\n",
      "TRAIN epoch: 1/3 iter 1800/2400 \t loss: 0.1084, acc: 96.88\n",
      "TRAIN epoch: 1/3 iter 2000/2400 \t loss: 0.1210, acc: 96.06\n",
      "TRAIN epoch: 1/3 iter 2200/2400 \t loss: 0.1006, acc: 97.06\n",
      "TRAIN epoch: 1/3 iter 2400/2400 \t loss: 0.0737, acc: 97.68\n",
      "TRAIN epoch: 2/3 iter 200/2400 \t loss: 0.0832, acc: 97.60\n",
      "TRAIN epoch: 2/3 iter 400/2400 \t loss: 0.0813, acc: 97.42\n",
      "TRAIN epoch: 2/3 iter 600/2400 \t loss: 0.0873, acc: 97.36\n",
      "TRAIN epoch: 2/3 iter 800/2400 \t loss: 0.0766, acc: 97.54\n",
      "TRAIN epoch: 2/3 iter 1000/2400 \t loss: 0.0775, acc: 97.62\n",
      "TRAIN epoch: 2/3 iter 1200/2400 \t loss: 0.0743, acc: 97.86\n",
      "TRAIN epoch: 2/3 iter 1400/2400 \t loss: 0.0729, acc: 97.88\n",
      "TRAIN epoch: 2/3 iter 1600/2400 \t loss: 0.0810, acc: 97.70\n",
      "TRAIN epoch: 2/3 iter 1800/2400 \t loss: 0.0758, acc: 97.68\n",
      "TRAIN epoch: 2/3 iter 2000/2400 \t loss: 0.0794, acc: 97.56\n",
      "TRAIN epoch: 2/3 iter 2200/2400 \t loss: 0.0707, acc: 97.90\n",
      "TRAIN epoch: 2/3 iter 2400/2400 \t loss: 0.0524, acc: 98.44\n",
      "\n",
      "Final training accuracy: 96.68%\n",
      "Final testing accuracy: 95.76%\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= 25)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size= 1000)\n",
    "\n",
    "\n",
    "\n",
    "# Build MLP\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')\n",
    "\n",
    "# Train MLP\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "train_a_model(mlp, num_epoch=3)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate MLP\n",
    "mlp.train(False)\n",
    "mlp.eval() # toggle evaluation mode\n",
    "# define an evaluation function\n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(mlp, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(mlp, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN structure you built is as follow: \n",
      "CNN(\n",
      "  (C1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (P2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (C3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (P4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (F5): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (F6): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (F7): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "       \n",
    "\n",
    "\n",
    "        self.C1 = nn.Conv2d(in_channels= 1, out_channels= 6, kernel_size= 5, padding= 2)\n",
    "        self.P2 = nn.MaxPool2d(kernel_size= 2, stride=2)\n",
    "        self.C3 = nn.Conv2d(in_channels= 6, out_channels= 16, kernel_size= 5, padding= 0)\n",
    "        self.P4 = nn.MaxPool2d(kernel_size= 2, stride= 2)\n",
    "        self.F5 = nn.Linear(in_features= 16*5*5, out_features= 120)\n",
    "        self.F6 = nn.Linear(in_features= 120, out_features= 84)\n",
    "        self.F7 = nn.Linear(in_features= 84, out_features= 10)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.C1(x))\n",
    "        x = self.P2(x)\n",
    "        x = F.relu(self.C3(x))\n",
    "        x = self.P4(x)\n",
    "        x = torch.flatten(x, start_dim= 1)\n",
    "        x = self.F5(x)\n",
    "        x = self.F6(x)\n",
    "        x = self.F7(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code way of doing (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters are: 61706\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of parameters are:\", count_parameters(cnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (f)\n",
    "Note: run this code after code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN structure you built is as follow: \n",
      "CNN(\n",
      "  (C1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (P2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (C3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (P4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (F5): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (F6): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (F7): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "TRAIN epoch: 0/3 iter 200/300 \t loss: 1.0559, acc: 66.85\n",
      "TRAIN epoch: 1/3 iter 200/300 \t loss: 0.1641, acc: 95.03\n",
      "TRAIN epoch: 2/3 iter 200/300 \t loss: 0.1052, acc: 96.81\n",
      "\n",
      "Final training accuracy: 97.19%\n",
      "Final testing accuracy: 97.02%\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=200)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1000)\n",
    "\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')\n",
    "\n",
    "# Train CNN\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the CNN for 3 epochs\n",
    "train_a_model(cnn, num_epoch=3)\n",
    "#######################\n",
    "\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn.eval() # toggle evaluation mode\n",
    "# define an evaluation function\n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(cnn, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(cnn, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae69442b1fc44f14b5ed9e4e267de3f8165086ea0eeb0bf8dc28231d964179e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
