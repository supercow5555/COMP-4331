{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "Note: \n",
    "1. It is ok to define more helper functions, but not necessary for finishing the homework.\n",
    "2. The imported libraries are sufficient to complete the TODO intructions. Please consult TA Vincent Cheng for permission to use additional libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP structure you built is as follow: \n",
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        #######################\n",
    "        # TODO: initialize neural network components\n",
    "        input_dim = 1*28*28 \n",
    "        hidden_dim1 = 300 \n",
    "        hidden_dim2 = 100 \n",
    "        output_dim = 10 \n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=input_dim, out_features=hidden_dim1) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim1, out_features=hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=hidden_dim2, out_features=output_dim)   \n",
    "\n",
    "        #######################\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        #######################\n",
    "        # TODO: define forwarding of MLP\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        y = self.fc3(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "        #######################\n",
    "        return x\n",
    "\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')\n",
    "\n",
    "\n",
    "\n",
    "##The number of parameters are: 78*300 + 300*100 + 100*10  + Bias terms --> Bias terms = 300 + 100 + 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (c)\n",
    "Note: run this code after code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP structure you built is as follow: \n",
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Final training accuracy: 96.68%\n",
      "Final testing accuracy: 95.76%\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "\n",
    "#######################\n",
    "# TODO: define train_loader, test_loader using train_set, test_set, the utils.data.DataLoader function\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=25)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000)\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "# Build MLP\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')\n",
    "\n",
    "# Train MLP\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the MLP for 3 epochs\n",
    "\n",
    "\n",
    "for i_epoch in range(3):\n",
    "    mlp.train(True)\n",
    "    loss_list = [ ]\n",
    "    acc_list = [ ]\n",
    "    for i_iter, (x, y_true) in enumerate (train_loader, start=1):\n",
    "        y_pred = mlp.forward(x)\n",
    "        loss = F.cross_entropy(y_pred, y_true)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "#######################\n",
    "\n",
    "# Evaluate MLP\n",
    "mlp.eval() # toggle evaluation mode\n",
    "# define an evaluation function\n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(mlp, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(mlp, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN structure you built is as follow: \n",
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        #######################\n",
    "        # TODO: initialize neural network components\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(in_features=16*5*5, out_features=10)\n",
    "        \n",
    "        #######################\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #######################\n",
    "        # TODO: define forwarding for CNN\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        y = self.fc(x)\n",
    "        return y \n",
    "\n",
    "        #######################\n",
    "\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (f)\n",
    "Note: run this code after code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN structure you built is as follow: \n",
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Final training accuracy: 98.35%\n",
      "Final testing accuracy: 98.30%\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "#######################\n",
    "# TODO: define the train_loader, test_loader using train_set, test_set, the utils.data.DataLoader function\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=25)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000)\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')\n",
    "\n",
    "# Train CNN\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the CNN for 3 epochs\n",
    "\n",
    "for i_epoch in range(3):\n",
    "    cnn.train(True)\n",
    "    loss_list = [ ]\n",
    "    acc_list = [ ]\n",
    "    for i_iter, (x, y_true) in enumerate (train_loader, start=1):\n",
    "        y_pred = cnn.forward(x)\n",
    "        loss = F.cross_entropy(y_pred, y_true)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn.eval() # toggle evaluation mode\n",
    "# define an evaluation function\n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(cnn, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(cnn, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae69442b1fc44f14b5ed9e4e267de3f8165086ea0eeb0bf8dc28231d964179e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
