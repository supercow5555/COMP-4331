{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "Note: \n",
    "1. It is ok to define more helper functions, but not necessary for finishing the homework.\n",
    "2. The imported libraries are sufficient to complete the TODO intructions. Please consult TA Vincent Cheng for permission to use additional libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP structure you built is as follow: \n",
      "MLP(\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        #######################\n",
    "        # TODO: initialize neural network components\n",
    "\n",
    "        # as all MNIST data are 1*28*28 pixel, then classify into 10 digits\n",
    "        input_dim = 1*28*28 \n",
    "        hidden1_dim = 300\n",
    "        hidden2_dim = 100\n",
    "        output_dim = 10\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=input_dim,out_features=hidden1_dim)\n",
    "        self.fc2 = nn.Linear(in_features=hidden1_dim, out_features= hidden2_dim)\n",
    "        self.fc3 = nn.Linear(in_features= hidden2_dim,out_features=output_dim)\n",
    "\n",
    "\n",
    "        #######################\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        #######################\n",
    "        # TODO: define forwarding of MLP\n",
    "        \n",
    "        x = torch.flatten(x,start_dim=1) #batch x 784\n",
    "        x = self.relu(self.fc1(x)) #batch x 300\n",
    "        x = self.relu(self.fc2(x)) #batch x 100\n",
    "        x = self.relu(self.fc3(x)) #batch x 10\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "        #######################\n",
    "\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (c)\n",
    "Note: run this code after code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "\n",
    "#######################\n",
    "# TODO: define train_loader, test_loader using train_set, test_set, the utils.data.DataLoader function\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=25)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1000)\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function which can be both useful in MLP and CNN case\n",
    "import numpy as np\n",
    "def count_acc(logits, label):\n",
    "                    pred = torch.argmax(logits, dim=1)\n",
    "                    return (pred == label).float().mean().item()\n",
    "\n",
    "def train_a_model (model,num_epochs = 3):\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        model.train(True)\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for i_iter, (x,y_true) in enumerate(train_loader,start=1):\n",
    "\n",
    "            # make prediction\n",
    "            y_pred = model.forward(x)\n",
    "            # compute loss\n",
    "            loss = lossFunc(y_pred,y_true)\n",
    "            # clear gradient to prevent accumulate\n",
    "            optimizer.zero_grad()\n",
    "            # apply backpropagation to compute gradients\n",
    "            loss.backward()\n",
    "            # update\n",
    "            optimizer.step()\n",
    "\n",
    "            #Extra, not included in the task, observe the training progress\n",
    "            acc= count_acc(y_pred,y_true)\n",
    "            loss_list.append(loss.item())\n",
    "            acc_list.append(acc)\n",
    "            if i_iter % 200 == 0:\n",
    "                loss_avg = np.sum(loss_list) / len(loss_list)\n",
    "                acc_avg = np.sum(acc_list) / len(acc_list)\n",
    "                msg = 'Train epoch: {}/{} iter: {}/{} \\t loss: {:.4f}, acc: {:.2f}%'.format(i_epoch,num_epochs,i_iter,len(train_loader),loss_avg,acc_avg*100)\n",
    "                print(msg)\n",
    "                loss_list = []\n",
    "                acc_list = []\n",
    "            \n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP structure you built is as follow: \n",
      "MLP(\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "Train epoch: 0/3 iter: 200/2400 \t loss: 1.6950, acc: 50.42%\n",
      "Train epoch: 0/3 iter: 400/2400 \t loss: 1.0753, acc: 63.54%\n",
      "Train epoch: 0/3 iter: 600/2400 \t loss: 1.0420, acc: 63.26%\n",
      "Train epoch: 0/3 iter: 800/2400 \t loss: 0.9535, acc: 65.08%\n",
      "Train epoch: 0/3 iter: 1000/2400 \t loss: 0.9443, acc: 65.48%\n",
      "Train epoch: 0/3 iter: 1200/2400 \t loss: 0.9158, acc: 66.14%\n",
      "Train epoch: 0/3 iter: 1400/2400 \t loss: 0.9077, acc: 66.36%\n",
      "Train epoch: 0/3 iter: 1600/2400 \t loss: 0.7143, acc: 74.96%\n",
      "Train epoch: 0/3 iter: 1800/2400 \t loss: 0.6915, acc: 74.56%\n",
      "Train epoch: 0/3 iter: 2000/2400 \t loss: 0.6820, acc: 74.94%\n",
      "Train epoch: 0/3 iter: 2200/2400 \t loss: 0.6571, acc: 75.50%\n",
      "Train epoch: 0/3 iter: 2400/2400 \t loss: 0.6140, acc: 76.04%\n",
      "Train epoch: 1/3 iter: 200/2400 \t loss: 0.6427, acc: 75.18%\n",
      "Train epoch: 1/3 iter: 400/2400 \t loss: 0.5960, acc: 77.24%\n",
      "Train epoch: 1/3 iter: 600/2400 \t loss: 0.6217, acc: 76.48%\n",
      "Train epoch: 1/3 iter: 800/2400 \t loss: 0.5779, acc: 77.54%\n",
      "Train epoch: 1/3 iter: 1000/2400 \t loss: 0.6005, acc: 76.66%\n",
      "Train epoch: 1/3 iter: 1200/2400 \t loss: 0.5799, acc: 77.26%\n",
      "Train epoch: 1/3 iter: 1400/2400 \t loss: 0.4935, acc: 82.20%\n",
      "Train epoch: 1/3 iter: 1600/2400 \t loss: 0.3708, acc: 86.68%\n",
      "Train epoch: 1/3 iter: 1800/2400 \t loss: 0.3828, acc: 85.88%\n",
      "Train epoch: 1/3 iter: 2000/2400 \t loss: 0.3798, acc: 86.18%\n",
      "Train epoch: 1/3 iter: 2200/2400 \t loss: 0.3704, acc: 86.32%\n",
      "Train epoch: 1/3 iter: 2400/2400 \t loss: 0.3438, acc: 86.42%\n",
      "Train epoch: 2/3 iter: 200/2400 \t loss: 0.3543, acc: 86.58%\n",
      "Train epoch: 2/3 iter: 400/2400 \t loss: 0.3412, acc: 87.00%\n",
      "Train epoch: 2/3 iter: 600/2400 \t loss: 0.3503, acc: 86.90%\n",
      "Train epoch: 2/3 iter: 800/2400 \t loss: 0.3212, acc: 87.60%\n",
      "Train epoch: 2/3 iter: 1000/2400 \t loss: 0.3260, acc: 87.46%\n",
      "Train epoch: 2/3 iter: 1200/2400 \t loss: 0.3222, acc: 87.82%\n",
      "Train epoch: 2/3 iter: 1400/2400 \t loss: 0.3284, acc: 87.28%\n",
      "Train epoch: 2/3 iter: 1600/2400 \t loss: 0.3183, acc: 87.82%\n",
      "Train epoch: 2/3 iter: 1800/2400 \t loss: 0.3350, acc: 86.94%\n",
      "Train epoch: 2/3 iter: 2000/2400 \t loss: 0.3246, acc: 87.52%\n",
      "Train epoch: 2/3 iter: 2200/2400 \t loss: 0.3274, acc: 87.08%\n",
      "Train epoch: 2/3 iter: 2400/2400 \t loss: 0.3163, acc: 87.26%\n",
      "\n",
      "Final training accuracy: 87.19%\n",
      "Final testing accuracy: 86.69%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build MLP\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')\n",
    "\n",
    "# Train MLP\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the MLP for 3 epochs\n",
    "train_a_model(mlp, num_epochs=3)\n",
    "#######################\n",
    "\n",
    "# Evaluate MLP\n",
    "mlp.eval() # toggle evaluation mode\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(mlp, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(mlp, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN structure you built is as follow: \n",
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        #######################\n",
    "        # TODO: initialize neural network components\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,padding=2)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,padding=0)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2,stride= 2)\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5,out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120,out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84,out_features=10)\n",
    "\n",
    "        #######################\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #######################\n",
    "        # TODO: define forwarding for CNN\n",
    "        # x = 1*28*28\n",
    "        x = F.relu(self.conv1(x)) # C1: batch*6*28*28\n",
    "        x = self.max_pool1(x) # P2: batch*6*14*14\n",
    "        x = F.relu(self.conv2(x)) # C3: batch*16*10*10\n",
    "        x = self.max_pool2(x) # P4: batch*16*5*5\n",
    "        x = torch.flatten(x,start_dim=1) # flatten P4: batch*400\n",
    "        x = self.fc1(x) # F5: batch*120\n",
    "        x = self.fc2(x) # F6: batch*84\n",
    "        x = self.fc3(x) # F7: batch*10\n",
    "        \n",
    "        #######################\n",
    "\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (f)\n",
    "Note: run this code after code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN structure you built is as follow: \n",
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Train epoch: 0/3 iter: 200/300 \t loss: 1.0559, acc: 66.85%\n",
      "Train epoch: 1/3 iter: 200/300 \t loss: 0.1640, acc: 95.03%\n",
      "Train epoch: 2/3 iter: 200/300 \t loss: 0.1053, acc: 96.81%\n",
      "\n",
      "Final training accuracy: 97.19%\n",
      "Final testing accuracy: 97.04%\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# TODO: define the train_loader, test_loader using train_set, test_set, the utils.data.DataLoader function\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=200)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1000)\n",
    "#######################\n",
    "\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')\n",
    "\n",
    "# Train CNN\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the CNN for 3 epochs\n",
    "train_a_model(cnn,num_epochs=3)\n",
    "#######################\n",
    "\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn.eval() # toggle evaluation mode\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(cnn, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(cnn, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f7248dda44c9aca490d825e08e1c8b901064e5575a7eb735a794e1a698a65ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('comp4331': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
